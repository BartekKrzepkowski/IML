{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Lab 6 - Getting familiar with assignment data\n",
        "\n",
        "In this lab we will focus on the first graded assignment, you can find the task at this link: \\\n",
        "https://knowledgepit.ml/iml2022project1/\n",
        "\n",
        "You should enroll to the task with the code:\n",
        "IML2022project1\n",
        "\n",
        "Please start by reading the assignemnt task description."
      ],
      "metadata": {
        "id": "WXEL2bj5Tldi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your job is to create an activel learning batch selection algorithm maximizing the improvement of the predefined model on 3 different sized batches:\n",
        "50, 200, and 500 samples.\n",
        "\n",
        "Predefined model is an XGBoost with 100 learning rounds.\n",
        "\n",
        "You are given an initial labeled pool that will be used to train the model and a data pool from which you should choose all of the samples."
      ],
      "metadata": {
        "id": "_k42XPEYUFha"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets start by loading the data into numpy array with with scipy library.\n",
        "\n",
        "See:\n",
        "https://docs.scipy.org/doc/scipy/reference/generated/scipy.io.mmread.html"
      ],
      "metadata": {
        "id": "nkoLSntDW_HT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tbVphKyTjGa",
        "outputId": "291517bb-bb60-4649-a335-ca93c76450d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Init batch shape (2000, 11436)\n",
            "Number of non zero values 122993\n",
            "Average number of values per row 61.4965\n"
          ]
        }
      ],
      "source": [
        "from scipy.io import mmread\n",
        "import numpy as np\n",
        "\n",
        "initial_batch = mmread('initial_batch_data.mtx')\n",
        "print(f\"Init batch shape {initial_batch.shape}\")\n",
        "print(f\"Number of non zero values {initial_batch.getnnz()}\")\n",
        "print(f\"Average number of values per row {np.mean(initial_batch.getnnz(axis=1))}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Please note that as the read matrix is in COOrdinate sparse format we cannot run the following command\n",
        "initial_batch[:10, :10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "Bqfog2zFYDMK",
        "outputId": "fc80b9fc-e2a9-466a-e2d0-4a5888fe78d6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-39273fcca909>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Please note that as the read matrix is in COOrdinate format we cannot run the following command\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minitial_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'coo_matrix' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If we wish to slice the matrix we should convert it o another format e.g. CSR format\n",
        "initial_batch = initial_batch.tocsr()\n",
        "initial_batch[:10, :10].todense()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pKkanKbZG_Z",
        "outputId": "addb2214-b58d-4fba-cb99-2bcf667199e6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.26352642, 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.29295912, 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.15879782],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.37624408, 0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.23856982, 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.32167849, 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Values in the data matrix are the documents in **tf-idf** format.(**term frequencyâ€“inverse document frequency**)\n",
        "\n",
        "You can read more about the format https://en.wikipedia.org/wiki/Tf%E2%80%93idf\n",
        "\n",
        "In practice we can compute the value as follows."
      ],
      "metadata": {
        "id": "o67WlJGHbVvL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets consider a follwing set documents\n",
        "doc1 = \"Alice has a cat\"\n",
        "doc2 = \"The cat would like to eat the mouse\"\n",
        "doc3 = \"\"\"How much wood could a woodchuck chuck\n",
        "If a woodchuck could chuck wood?\n",
        "As much wood as a woodchuck could chuck,\n",
        "If a woodchuck could chuck wood.\"\"\"\n",
        "\n",
        "corpus = [doc1, doc2, doc3]"
      ],
      "metadata": {
        "id": "ExBcB6ZObUyC"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "count_vectorizer = CountVectorizer()\n",
        "word_counts = count_vectorizer.fit_transform(corpus)\n",
        "word_counts.todense()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTOoWWB-iNhI",
        "outputId": "9e17908f-dc7a-4976-d222-ff9711a31d3b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 2, 1, 0, 0, 1],\n",
              "        [0, 2, 0, 4, 4, 0, 0, 1, 2, 0, 0, 2, 0, 0, 4, 4, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_vectorizer.vocabulary_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1B5X9vG4i87u",
        "outputId": "3d2ff938-79e7-4533-8f49-be2c8c729563"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'alice': 0,\n",
              " 'as': 1,\n",
              " 'cat': 2,\n",
              " 'chuck': 3,\n",
              " 'could': 4,\n",
              " 'eat': 5,\n",
              " 'has': 6,\n",
              " 'how': 7,\n",
              " 'if': 8,\n",
              " 'like': 9,\n",
              " 'mouse': 10,\n",
              " 'much': 11,\n",
              " 'the': 12,\n",
              " 'to': 13,\n",
              " 'wood': 14,\n",
              " 'woodchuck': 15,\n",
              " 'would': 16}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "tfid = TfidfTransformer().fit_transform(word_counts)\n",
        "tfid.todense()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pcs7HtbujUg9",
        "outputId": "13434d18-541e-4bc3-8ca3-c4377cee4672"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[0.62276601, 0.        , 0.4736296 , 0.        , 0.        ,\n",
              "         0.        , 0.62276601, 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.24573525, 0.        , 0.        ,\n",
              "         0.32311233, 0.        , 0.        , 0.        , 0.32311233,\n",
              "         0.32311233, 0.        , 0.64622465, 0.32311233, 0.        ,\n",
              "         0.        , 0.32311233],\n",
              "        [0.        , 0.22792115, 0.        , 0.45584231, 0.45584231,\n",
              "         0.        , 0.        , 0.11396058, 0.22792115, 0.        ,\n",
              "         0.        , 0.22792115, 0.        , 0.        , 0.45584231,\n",
              "         0.45584231, 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Or you can do this in one step using TfidfVectorizer \\\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn-feature-extraction-text-tfidfvectorizer"
      ],
      "metadata": {
        "id": "5wpPX1Ndj6MI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets now load the labels"
      ],
      "metadata": {
        "id": "2fCs3ZkIkvql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = []\n",
        "\n",
        "with open('initial_batch_labels.txt', 'r') as f:\n",
        "  for line in f:\n",
        "    labels.append(line.strip().split(','))\n"
      ],
      "metadata": {
        "id": "Uxoutz4skoC5"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "lb = MultiLabelBinarizer()\n",
        "\n",
        "labels_binary = lb.fit_transform(labels)\n",
        "labels_binary[:2], labels[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_Rs4wVrnDeA",
        "outputId": "8c767cd0-f3e3-45d0-b13a-8bcae0ad5105"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0]]), [['F', 'G', 'I'], ['F', 'G']])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try to create an active learning batch selection algorithm for the assignemnt.\n",
        "\n",
        "Tips:\n",
        "1. You can split the initial_batch in 3 parts and use one part for evaluation purposes and one as a pool\n",
        "2. When desigining an algorithm you can test its generalization performance on another fully labeled datasets first. It may be a good idea to use some NLP problem to work on simillar representation. "
      ],
      "metadata": {
        "id": "VxeniIzNnmvZ"
      }
    }
  ]
}