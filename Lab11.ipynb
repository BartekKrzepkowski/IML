{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab11.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lab11 - Self-supervised learning\n",
        "\n",
        "In todays lab scenario we will focus on part of semi-supervised learning called self-supervised learning which focuses on learning representation from unlabeled data.\n",
        "\n",
        "Particularly we will implement RotNet - a neural network that tries to learn meaningful embedding of the image by solving a \"pretext\" task of rotation prediction.\n",
        "\n",
        "You can read more about the idea here: https://arxiv.org/abs/2012.01985v2\n",
        "\n",
        "After learning the representation we will use it in semi-supervised scenario and comapre with an algorithm using only the supervised part of the dataset."
      ],
      "metadata": {
        "id": "VHyoj6QoFadC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "We will implement our models for [Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist) dataset, so lets start by downloading the data."
      ],
      "metadata": {
        "id": "tUZ2iGqcGy8W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1yZMugwFG_t"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "import torch\n",
        "\n",
        "from torchvision import transforms\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "fashion_mnist_data_train_raw = torchvision.datasets.FashionMNIST('./data', train=True, download=True, transform=transform)\n",
        "\n",
        "fashion_mnist_data_test = torchvision.datasets.FashionMNIST('./data', train=False, download=True, transform=transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To properly perform the experiment we will split our training data to simulate that we do not have labels for majority of them."
      ],
      "metadata": {
        "id": "IFL4o8F5LQCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.dataset import Dataset\n",
        "\n",
        "train_size = int(0.02 * len(fashion_mnist_data_train_raw))\n",
        "train_indices = torch.randperm(len(fashion_mnist_data_train_raw))[:train_size]\n",
        "fashion_mnist_data_train = torch.utils.data.Subset(fashion_mnist_data_train_raw, train_indices)\n",
        "\n",
        "class PoolDataset(Dataset):\n",
        "  def __init__(self, dataset_to_hide_labels):\n",
        "    self.dataset = dataset_to_hide_labels\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    X, y = self.dataset[index]\n",
        "    return X\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dataset)\n",
        "\n",
        "fashion_mnist_data_pool = PoolDataset(fashion_mnist_data_train_raw)\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(fashion_mnist_data_train,\n",
        "                                          batch_size=64,\n",
        "                                          shuffle=True,\n",
        "                                          num_workers=2)\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(fashion_mnist_data_test,\n",
        "                                          batch_size=64,\n",
        "                                          shuffle=False,\n",
        "                                          num_workers=2)"
      ],
      "metadata": {
        "id": "alH4WknqMHhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will define a simple neural network that will be our model for representation learning. We will reuse some chunks of code from lab7."
      ],
      "metadata": {
        "id": "hFCYJ1QtKghm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "model = nn.Sequential(\n",
        "          nn.Conv2d(1,32, 3),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(2),\n",
        "          nn.Dropout(),\n",
        "          nn.Conv2d(32,64, 3),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(2),\n",
        "          nn.Dropout(),\n",
        "          nn.Conv2d(64, 32, 3),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(2),\n",
        "          nn.Flatten(),\n",
        "          nn.Dropout(),\n",
        "          nn.Linear(32, 10)\n",
        "        )\n",
        "model = model.float()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "R8PFB2z-KSeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can define below functions for training and evaluation with created NN."
      ],
      "metadata": {
        "id": "I7Fui9H_LE3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import balanced_accuracy_score\n",
        "\n",
        "def train_loop(dataloader, model, loss_fn, optimizer, num_epochs=1):\n",
        "    size = len(dataloader.dataset)\n",
        "    for epoch in range(num_epochs):\n",
        "      for batch, (X, y) in enumerate(dataloader):\n",
        "          pred = model(X)\n",
        "          loss = loss_fn(pred, y)\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          if batch % 100 == 0:\n",
        "              loss, current = loss.item(), batch * len(X)\n",
        "              print(f\"Epoch {epoch}, loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, labels_estimated, correct_labels = 0, [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct_labels.extend(y.numpy())\n",
        "            labels_estimated.extend((pred.argmax(1)).numpy())\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    print(f\"Test Error: \\n BAC: {balanced_accuracy_score(correct_labels, labels_estimated)} \\n Loss {test_loss}\")"
      ],
      "metadata": {
        "id": "rXL8Foq0KdQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Train a classifier on the training set and evaluate its performance."
      ],
      "metadata": {
        "id": "UyAvKLbcRKf3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gI1iewo5LpVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Train a RotNet on the pool data.\n",
        "\n",
        "We can model RotNet as classifier with categorical output predicting the following categories:\n",
        "- Image wasn't rotated\n",
        "- Image was rotated by 90 degrees\n",
        "- Image was rotated by 180 degrees\n",
        "- Image was rotated by 270 degrees\n",
        "\n",
        "Artificially create a label for each sample from the data pool during the training process."
      ],
      "metadata": {
        "id": "A2MPOpX2YKkP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "klIU2i6JW3ac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Fine tune the RotNet network to the downstream task - fashion categories classification. Evaluate obtained network on the test set."
      ],
      "metadata": {
        "id": "5lODQRS-Y0Dk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "K7YvoOATZGrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.* Try to add another head to the self-supervised network that learns another \"pretext\" task."
      ],
      "metadata": {
        "id": "c9-RtlkpZMRg"
      }
    }
  ]
}